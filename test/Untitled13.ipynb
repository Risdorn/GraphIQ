{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncBDgkbIvq9y",
        "outputId": "c5b12c89-b5f7-4d0c-c8bb-5e5878a02ab1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available. Installing faiss-gpu (best-effort).\n",
            "Install step finished. Restart runtime if required by Colab prompts.\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies. If GPU runtime with CUDA is present, install faiss-gpu, otherwise faiss-cpu.\n",
        "import sys, subprocess, os\n",
        "\n",
        "# pinned versions you gave\n",
        "reqs = {\n",
        "    \"fastapi\": \"fastapi==0.122.0\",\n",
        "    \"google-genai\": \"google-genai==1.52.0\",\n",
        "    \"neo4j\": \"neo4j==5.28.2\",\n",
        "    \"numpy\": \"numpy==2.2.5\",\n",
        "    \"openai\": \"openai==1.101.0\",\n",
        "    \"pdfplumber\": \"pdfplumber==0.11.8\",\n",
        "    \"pydantic\": \"pydantic==2.11.7\",\n",
        "    \"python-dotenv\": \"python-dotenv==1.1.1\",\n",
        "    \"python-docx\": \"python-docx==1.2.0\",\n",
        "    \"python-multipart\": \"python-multipart==0.0.20\",\n",
        "    \"uvicorn\": \"uvicorn==0.38.0\",\n",
        "    \"sentence-transformers\": \"sentence-transformers\",  # leave latest compatible\n",
        "}\n",
        "\n",
        "# Install core packages\n",
        "pkgs = list(reqs.values()) + [\"faiss-cpu==1.13.0\"]  # default to CPU; we may upgrade to GPU below\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\"], check=True)\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\"] + pkgs, check=True)\n",
        "\n",
        "# Try to detect CUDA and install faiss-gpu if available (best-effort)\n",
        "try:\n",
        "    import torch\n",
        "    cuda_available = torch.cuda.is_available()\n",
        "except Exception:\n",
        "    cuda_available = False\n",
        "\n",
        "if cuda_available:\n",
        "    print(\"CUDA available. Installing faiss-gpu (best-effort).\")\n",
        "    # Remove faiss-cpu and install faiss-gpu compatible with system (best-effort)\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"faiss-gpu\"], check=False)\n",
        "else:\n",
        "    print(\"CUDA NOT available or torch not installed; using faiss-cpu.\")\n",
        "\n",
        "# Finally ensure sentence-transformers installed\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"sentence-transformers\"], check=True)\n",
        "\n",
        "print(\"Install step finished. Restart runtime if required by Colab prompts.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# ---- Your provided keys (safe only because YOU explicitly requested it) ----\n",
        "os.environ[\"NEO4J_URI\"] = \"neo4j+s://d3e57ec4.databases.neo4j.io\"\n",
        "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
        "os.environ[\"NEO4J_PASSWORD\"] = \"FKCI-m1vsaNZh5Mkz1F4yVYzBhGMQDqPsHVvxH_3aGw\"\n",
        "os.environ[\"NEO4J_DATABASE\"] = \"neo4j\"\n",
        "\n",
        "os.environ[\"AURA_INSTANCEID\"] = \"d3e57ec4\"\n",
        "os.environ[\"AURA_INSTANCENAME\"] = \"Free instance\"\n",
        "\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = \"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\"\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyCUL9mtLwsZhhygtCwaC4yrtzjb-X1xc3I\"\n",
        "\n",
        "print(\"All keys loaded into environment variables.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VToRAKnq4VNO",
        "outputId": "db0ef92b-e7f1-4238-ba61-08b68ab9cc8e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All keys loaded into environment variables.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from neo4j import GraphDatabase\n",
        "import os\n",
        "\n",
        "NEO4J_URI = os.environ[\"NEO4J_URI\"]\n",
        "NEO4J_USERNAME = os.environ[\"NEO4J_USERNAME\"]\n",
        "NEO4J_PASSWORD = os.environ[\"NEO4J_PASSWORD\"]\n",
        "\n",
        "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
        "print(\"Neo4j Connected Successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgzKNlPX5_Nh",
        "outputId": "d3502a15-64b2-4990-80f7-f6462be74b1f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neo4j Connected Successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "import os\n",
        "\n",
        "GEMINI_API_KEY = os.environ[\"GEMINI_API_KEY\"]\n",
        "\n",
        "client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "print(\"Gemini Client Ready!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPNjRoxF6CL1",
        "outputId": "5350a9e9-9469-4d22-dbce-9af884fe3606"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini Client Ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "client_or = OpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=os.environ[\"OPENROUTER_API_KEY\"])\n",
        "print(\"OpenRouter Client Ready!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLBn2L606Em3",
        "outputId": "7feedc82-964d-41cc-b89a-39c647cb6429"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenRouter Client Ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from embed_retrieval_role import build_index_from_json, hybrid_retrieve\n",
        "import json\n",
        "\n",
        "with open(\"chunks.json\",\"r\") as f:\n",
        "    chunks = json.load(f)\n",
        "\n",
        "print(build_index_from_json(chunks, save_prefix=\"emb_index\"))\n",
        "out = hybrid_retrieve(\"How does hybrid retrieval work?\", top_k=5, index_prefix=\"emb_index\", use_graph=True)\n",
        "print(json.dumps(out, indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ylLi8U36IHC",
        "outputId": "6cd45e79-9203-4545-80ee-8a3a8c712467"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini embedding failed, falling back to local hashing embedding. Error: 'Client' object has no attribute 'embeddings'\n",
            "{'status': 'ok', 'saved_prefix': 'emb_index', 'count': 8, 'embed_dim': 512, 'used_gemini': True}\n",
            "Gemini embedding failed, falling back to local hashing embedding. Error: 'Client' object has no attribute 'embeddings'\n",
            "{\n",
            "  \"query\": \"How does hybrid retrieval work?\",\n",
            "  \"results\": [\n",
            "    {\n",
            "      \"index\": 2,\n",
            "      \"chunk_id\": \"chunk_003\",\n",
            "      \"score\": 0.3507530689239502,\n",
            "      \"text\": \"Hybrid retrieval combines vector search and graph evidence from Neo4j to rank chunks relevant to the query.\",\n",
            "      \"meta\": {\n",
            "        \"source\": \"fake_pdf\",\n",
            "        \"page\": 2,\n",
            "        \"entities\": [\n",
            "          \"hybrid retrieval\",\n",
            "          \"Neo4j\"\n",
            "        ]\n",
            "      },\n",
            "      \"graph_evidence\": [],\n",
            "      \"combined_score\": 0.3507530689239502\n",
            "    },\n",
            "    {\n",
            "      \"index\": 7,\n",
            "      \"chunk_id\": \"chunk_008\",\n",
            "      \"score\": 0.3418099880218506,\n",
            "      \"text\": \"Using a GPU-accelerated FAISS index allows the retrieval agent to answer queries in milliseconds even on large datasets.\",\n",
            "      \"meta\": {\n",
            "        \"source\": \"fake_pdf\",\n",
            "        \"page\": 4,\n",
            "        \"entities\": [\n",
            "          \"FAISS\",\n",
            "          \"GPU\"\n",
            "        ]\n",
            "      },\n",
            "      \"graph_evidence\": [],\n",
            "      \"combined_score\": 0.3418099880218506\n",
            "    },\n",
            "    {\n",
            "      \"index\": 6,\n",
            "      \"chunk_id\": \"chunk_007\",\n",
            "      \"score\": 0.3000638782978058,\n",
            "      \"text\": \"The embedding agent produces numerical vector representations of text that capture semantic meaning for downstream retrieval.\",\n",
            "      \"meta\": {\n",
            "        \"source\": \"fake_pdf\",\n",
            "        \"page\": 4,\n",
            "        \"entities\": [\n",
            "          \"embedding agent\",\n",
            "          \"semantic meaning\"\n",
            "        ]\n",
            "      },\n",
            "      \"graph_evidence\": [],\n",
            "      \"combined_score\": 0.3000638782978058\n",
            "    },\n",
            "    {\n",
            "      \"index\": 5,\n",
            "      \"chunk_id\": \"chunk_006\",\n",
            "      \"score\": 0.2756861448287964,\n",
            "      \"text\": \"Neo4j stores nodes and relationships in a labeled property graph structure that helps the system perform graph traversal for retrieval.\",\n",
            "      \"meta\": {\n",
            "        \"source\": \"fake_pdf\",\n",
            "        \"page\": 3,\n",
            "        \"entities\": [\n",
            "          \"Neo4j\",\n",
            "          \"graph traversal\"\n",
            "        ]\n",
            "      },\n",
            "      \"graph_evidence\": [],\n",
            "      \"combined_score\": 0.2756861448287964\n",
            "    },\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"chunk_id\": \"chunk_001\",\n",
            "      \"score\": 0.17936056852340698,\n",
            "      \"text\": \"GraphIQ is an agentic AI system that extracts entities and relations from documents and stores them inside a Neo4j knowledge graph.\",\n",
            "      \"meta\": {\n",
            "        \"source\": \"fake_pdf\",\n",
            "        \"page\": 1,\n",
            "        \"entities\": [\n",
            "          \"GraphIQ\",\n",
            "          \"Neo4j\",\n",
            "          \"agentic AI\"\n",
            "        ]\n",
            "      },\n",
            "      \"graph_evidence\": [],\n",
            "      \"combined_score\": 0.17936056852340698\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nXiQY1XQ7foB"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}